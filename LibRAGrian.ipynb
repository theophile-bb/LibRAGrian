{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# LibRAGrian : Building a RAG pipeline with Chonkie Chunker & Faiss"
      ],
      "metadata": {
        "id": "BxqodLfAPeIq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installs"
      ],
      "metadata": {
        "id": "9i__9f47QJEZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "!git clone https://github.com/theophile-bb/LibRAGrian.git\n",
        "%cd LibRAGrian"
      ],
      "metadata": {
        "id": "cwRQlOalQLYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "9cQ72Mn8ydm1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"src\")\n",
        "\n",
        "# Utils\n",
        "from utils import *"
      ],
      "metadata": {
        "id": "RWK8ipvVgaQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rEuis0EYFfym"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we have to get the book dataset. We'll retrieve it using the Hugginface and start the processing.\n",
        "\n",
        "Dataset : https://huggingface.co/datasets/stas/gutenberg-100"
      ],
      "metadata": {
        "id": "mEYmC3eMPr0v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Login using e.g. `huggingface-cli login` to access this dataset\n",
        "df = pd.read_csv(\"hf://datasets/stas/gutenberg-100/books-100.csv\")"
      ],
      "metadata": {
        "id": "HldTOcE99kxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "AdMRgAku9neI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "kJ18kKGi5aoZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text processing and cleaning"
      ],
      "metadata": {
        "id": "Nr6nnSHj5cVi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We keep the relevant columns and remove the book duplicates."
      ],
      "metadata": {
        "id": "Vk8SC0eFtG4r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "book_df = df[['title','author','text']]\n",
        "book_df = book_df.drop_duplicates(subset=[\"title\",\"author\"])"
      ],
      "metadata": {
        "id": "njewkSXlEByg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "book_df"
      ],
      "metadata": {
        "id": "su9yJXgkELrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We then have to clean and strip the unnecessary parts of the texts.\n",
        "\n",
        "The cleaning part is as follow :\n",
        "- Decode the UTF-8 BOM text bytes to show punctuation.\n",
        "- Keep only the main text related to the book that is located between the *START OF THE PROJECT GUTENBERG EBOOK.* and *END OF THE PROJECT GUTENBERG EBOOK.* tags.\n",
        "- Remove ther unnecessary line jumps (*\\n*) to improve clarity.\n",
        "- Strip once again the redundant noise located at the beginning of the text. It includes : everything before the main title of the book, illustration description, translation and diffusion credits."
      ],
      "metadata": {
        "id": "3Ix171QGtOTW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply the processing to the whole text corpus."
      ],
      "metadata": {
        "id": "1rUMopR3wGxY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "book_df[\"cleaned_text\"] = book_df.apply(lambda row: Clean_book(row[\"text\"], row[\"title\"]),axis=1)"
      ],
      "metadata": {
        "id": "nalwEgn4aLzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We then proceed to filter the books to keep only the ones written in English."
      ],
      "metadata": {
        "id": "WVUmmRm9wN0c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "book_df['language'] = book_df['cleaned_text'].apply(detect)"
      ],
      "metadata": {
        "id": "T2E6YvHlEIrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "book_df = book_df[book_df['language'].isin(['en'])]\n",
        "book_df = book_df.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "sWQrFJlSmUU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "book_df"
      ],
      "metadata": {
        "id": "jnoTGRwYFm-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "ocofTklySXwj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chunking of the book"
      ],
      "metadata": {
        "id": "NI7H8OvMP2DA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next step is the chunking. For each book, we will chunk it and store the chunks into a dataframe with metadata."
      ],
      "metadata": {
        "id": "f-sX_gviwmIn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chunks_df = Create_chunk_df(book_df)"
      ],
      "metadata": {
        "id": "kvUqrn8viuQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunks_df.head()"
      ],
      "metadata": {
        "id": "GgbUjhPXjKVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "JezQgu9M5qo-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embedding of the chunks"
      ],
      "metadata": {
        "id": "zRm-84a3fVa8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We transform the chunks into embeddings usingthe bge small model."
      ],
      "metadata": {
        "id": "aHtDfuHy1fRm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embed_model = \"BAAI/bge-small-en-v1.5\"\n",
        "texts = chunks_df['chunk'].tolist()\n",
        "\n",
        "embeddings = Embedding(embed_model, texts, batch_size = 32)"
      ],
      "metadata": {
        "id": "Jdv-Ud01upVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunks_df[\"embedding\"] = embeddings"
      ],
      "metadata": {
        "id": "Ab9vJ4fmwzMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "Oj7ScQcL5szP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Index the embeddings with Faiss"
      ],
      "metadata": {
        "id": "T0N4uFthm-oU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We then create a Faiss index with the embeddings for retrieval using cosine similarity."
      ],
      "metadata": {
        "id": "ejcNOjFa15-8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index = Create_Faiss_index(embeddings)"
      ],
      "metadata": {
        "id": "ovMYh6-_xnky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "kMlXlujs5yRo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Retrieval with Qwen 2.5-3b"
      ],
      "metadata": {
        "id": "2IzOfBsunikf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The last step is the retrieval step. We use the embdding model to embed the query and retieve the k most relevant chunks. We then pass these chunks as well the context (title of the books and id of the chunks) to the generative model (here Qwen2.5-3B-Instruct) with a query wait for a reply to be generated."
      ],
      "metadata": {
        "id": "m6tOHM7D3JXg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gen_model = \"Qwen/Qwen2.5-3B-Instruct\"\n",
        "\n",
        "embed_model = load_embedding_model(embed_model)\n",
        "gen_tokenizer, gen_model, device = load_generation_model(gen_model)\n"
      ],
      "metadata": {
        "id": "Ruzi8JoVVwkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The RAG is now ready for querying !"
      ],
      "metadata": {
        "id": "HknbuAEqlKDn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Can you tell me all the Jules Verne books you have heard of ?\"\n",
        "#query = \"Who is the main character in the book Twenty Thousand Leagues Under the Seas ? Can you descibe him/her a bit ?\"\n",
        "#query = \"What is the plot about in the book The Strange Case of Dr. Jekyll and Mr. Hyde ?\"\n",
        "#query = \"What is the plot about in the book The Skylark of Space ?\"\n",
        "#query = \"Among all the books you know who is the most evil character you've seen ? The one with the least moral values or who causes the most pain.\"\n",
        "#query = \"In the novel The Time Machine, how long did it take to build the machine ?\"\n",
        "\n",
        "result = answer_query(\n",
        "    query=query,\n",
        "    embed_model=embed_model,\n",
        "    index=index,\n",
        "    chunks_df=chunks_df,\n",
        "    gen_model=gen_model,\n",
        "    gen_tokenizer=gen_tokenizer,\n",
        "    device=device\n",
        ")\n",
        "\n",
        "print(result[\"answer\"])\n",
        "print(result[\"sources\"])"
      ],
      "metadata": {
        "id": "iw4IR0Y1eM32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "ut989S2HV6nV"
      }
    }
  ]
}
